# スコアリングアルゴリズム詳解

本ドキュメントでは、Semantic Candidate Rankerで使用されるスコアリングアルゴリズムの詳細を解説します。

## 概要

各候補テキストは、2つの指標の重み付き合計によってスコアリングされます。

```
最終スコア = wA × 自然さスコア + wB × 参照近接スコア
```

## 1. 自然さスコア（Naturalness Score）

### 定義

参照文集合の**重心（centroid）**と候補テキストのコサイン類似度。

### 計算手順

1. 参照文（約300文）をそれぞれEmbeddingベクトルに変換
2. 全参照文ベクトルの平均を計算
3. 平均ベクトルをL2正規化して重心を得る
4. 候補テキストのEmbeddingと重心のコサイン類似度を計算

### 数式

```
centroid = normalize(Σ ref_embedding_i / N)

naturalness_score = cosine_similarity(candidate_embedding, centroid)
```

### 意図

- 「英語として自然な文」の平均的な特徴と比較
- 特定の参照文に偏らない全体的な評価
- 意味不明な文字列は重心から遠くなる

## 2. 参照近接スコア（Reference Proximity Score）

### 定義

候補テキストと最も類似する上位k個の参照文との平均類似度。

### 計算手順

1. 候補テキストと全参照文のコサイン類似度を計算
2. 類似度を降順ソート
3. 上位k個の平均を取る

### 数式

```
similarities = [cosine_similarity(candidate, ref_i) for ref_i in references]
top_k = sorted(similarities, descending=True)[:k]

proximity_score = Σ top_k / k
```

### 意図

- 偶然の一致を減らす（複数の参照文と類似している必要がある）
- 特定の表現パターンとの近さを評価
- kの値で厳密さを調整可能

## 3. プリセット設定

| プリセット | wA | wB | k | 特徴 |
|-----------|-----|-----|---|------|
| Balanced | 0.5 | 0.5 | 5 | 両指標を均等に評価 |
| Naturalness | 0.7 | 0.3 | 5 | 全体的な自然さを重視 |
| Reference | 0.3 | 0.7 | 5 | 具体的な表現との一致を重視 |
| Strict | 0.5 | 0.5 | 3 | 少数の参照文との高い一致を要求 |
| Broad | 0.5 | 0.5 | 7 | 多数の参照文との緩い一致を許容 |

## 4. スコアの正規化

コサイン類似度は[-1, 1]の範囲を取りますが、表示用に[0, 1]に正規化します。

```
display_score = (raw_score + 1) / 2
```

これにより：
- 1.0 = 完全に類似
- 0.5 = 無関係
- 0.0 = 意味的に反対

## 5. 信頼度（Confidence）

スコアとは別に、候補テキストの文字数に基づく信頼度を表示します。

| 信頼度 | 文字数 | 理由 |
|--------|--------|------|
| Low | < 40 | 短い文はEmbeddingの精度が低い |
| Medium | 40-120 | 標準的な長さ |
| High | > 120 | 十分な文脈情報がある |

## 6. 評価コメント

スコアに基づいて定性的な評価を表示します。

| 評価 | スコア範囲 | 解釈 |
|------|-----------|------|
| 優秀 | ≥ 0.85 | 非常に自然な英語表現 |
| 良好 | 0.75-0.85 | 自然で流暢な表現 |
| 普通 | 0.65-0.75 | やや自然、改善の余地あり |
| 弱い | 0.55-0.65 | やや不自然、要確認 |
| 不良 | < 0.55 | 自然な文ではない可能性が高い |

## 7. 計算量

- 参照文Embedding: O(N × d) - 初回のみ、キャッシュ
- 候補Embedding: O(M × d)
- 類似度計算: O(M × N × d)
- ソート: O(M × N log N)

ここで：
- N = 参照文数（約300）
- M = 候補数（最大200）
- d = Embedding次元（384）

## 8. 制限事項

- Embeddingモデルは英語に最適化されており、他言語では精度が低下
- 非常に短いテキスト（数単語）では信頼性が低い
- 専門用語や固有名詞が多い文は低スコアになりやすい
- スコアは絶対的な品質指標ではなく、相対的な比較に使用すべき
